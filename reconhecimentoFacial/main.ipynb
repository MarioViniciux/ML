{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c3571",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python mtcnn keras-facenet scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eca5de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee716bfb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path, size=(160, 160)):\n",
    "    img = cv2.imread(path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, size)\n",
    "    return img_resized\n",
    "\n",
    "def detect_faces(image):\n",
    "    detector = MTCNN()\n",
    "    return detector.detect_faces(image)\n",
    "\n",
    "embedder = FaceNet()\n",
    "\n",
    "def get_embedding(face_img_rgb):\n",
    "    return embedder.embeddings([face_img_rgb])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86ce95",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "os.makedirs(\"dataset\", exist_ok=True)\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    person_name = ''.join([c for c in filename if not c.isdigit()]).replace('.jpg', '').replace('.png', '')\n",
    "    person_folder = f'dataset/{person_name}'\n",
    "    os.makedirs(person_folder, exist_ok=True)\n",
    "    shutil.move(filename, os.path.join(person_folder, filename))\n",
    "\n",
    "print(\"Imagens organizadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10285a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = \"dataset\"\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for person in os.listdir(dataset_path):\n",
    "    person_path = os.path.join(dataset_path, person)\n",
    "    for img_name in os.listdir(person_path):\n",
    "        img_path = os.path.join(person_path, img_name)\n",
    "        img = load_and_preprocess_image(img_path)\n",
    "        embedding = get_embedding(img)\n",
    "        embeddings.append(embedding)\n",
    "        labels.append(person)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "joblib.dump(knn, \"knn_classifier.pkl\")\n",
    "\n",
    "print(\"Treinamento completo. Modelo salvo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564eadc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "img_path = list(uploaded.keys())[0]\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "detector = MTCNN()\n",
    "faces = detector.detect_faces(img_rgb)\n",
    "\n",
    "knn = joblib.load(\"knn_classifier.pkl\")\n",
    "\n",
    "for face in faces:\n",
    "    x, y, w, h = face['box']\n",
    "    face_crop = img_rgb[y:y+h, x:x+w]\n",
    "    face_crop = cv2.resize(face_crop, (160, 160))\n",
    "    embedding = get_embedding(face_crop)\n",
    "    prediction = knn.predict([embedding])[0]\n",
    "\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "    cv2.putText(img, prediction, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "\n",
    "cv2_imshow(img)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
